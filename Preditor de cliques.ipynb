{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preditor de cliques\n",
    "#### A ideia desse projeto é criar um algoritmo preditor de cliques. Preditores de cliques são importantes ferramentes em meio a publicidade, podendo se otimizar o impulsionamento de anuncios de acordo a perfis encontrados em meio a dados. \n",
    "#### Nesse modelo, será analisado um banco de dados https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/overview que nos propoe construir uma ferramenta que consiga prever possiveis cliques fraudulentos em anúnicos de aplicativos. \n",
    "#### Meu objetivo é criar um preditor de cliques estudandos os dados das bases de dados, onde ao final, usarei duas formas de predição e mostrarei a cobertura alcançada para prever se de fato os cliques que chegam ao seu objeitvo, o download do aplicativo que o anúncio se referia.\n",
    "\n",
    "#### O link para o git com as bases de dados: https://github.com/WillianAUK/regression_prediction_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas utilizadas no preditor ou para vizualização\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando funções responsaveis pelo treinamento do modelo através de regressão logística usando Gradiente descendente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função logistica\n",
    "def sigmoid(input):\n",
    "    return 1.0 / (1 + np.exp(-input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função que calcula a previsão y(x) dado os pesos.\n",
    "def compute_prediction(X, weights):\n",
    "    \"\"\" Calcule a previsão y_hat com base nos pesos atuais\n",
    "    Args:\n",
    "        X (numpy.ndarray)\n",
    "        weights (numpy.ndarray)\n",
    "    Returns:\n",
    "        numpy.ndarray, y_hat of X under weights \"\"\"\n",
    "    \n",
    "    z = np.dot(X, weights)\n",
    "    predictions = sigmoid(z)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função para continuar atualizando os pesos de acordo ao gardiente descendente. \n",
    "def update_weights_gd(X_train, y_train, weights, learning_rate):\n",
    "    \"\"\" Atualizar pesos em um passo\n",
    "    Args:\n",
    "        X_train, y_train (numpy.ndarray, training data set)\n",
    "        weights (numpy.ndarray)\n",
    "        learning_rate (float)\n",
    "    Returns:\n",
    "        numpy.ndarray, updated weights\"\"\"\n",
    "    \n",
    "    predictions = compute_prediction(X_train, weights)\n",
    "    weights_delta = np.dot(X_train.T, y_train - predictions)\n",
    "    m = y_train.shape[0]\n",
    "    weights += learning_rate / float(m) * weights_delta\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a definindo a função de calcula do custo j(w)\n",
    "def compute_cost(X, y, weights):\n",
    "    \"\"\" \n",
    "    Calcule o custo J (w)\n",
    "    Args:\n",
    "        X, y (numpy.ndarray, data set)\n",
    "        weights (numpy.ndarray)\n",
    "    Returns:\n",
    "        float \n",
    "    \"\"\"\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    cost = np.mean(-y * np.log(predictions) - (1 - y) * np.log(1 - predictions))\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que conecta as funções na função de treinamento do modelo, atualizando o vetor de pesos em cada iteração e \n",
    "# imprimindo o custo atual para cada 100 (podem ser outros valores) iterações afim de garantir que o custo está diminuindo \n",
    "# e que as coisas estão no caminho certo.\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n",
    "    \"\"\" \n",
    "    Treine um modelo de regressão linear com gradiente descendente\n",
    "    Args:\n",
    "        X_train, y_train (numpy.ndarray, conjunto de dados de treinamento)\n",
    "        Max_iter (int, número de iterações)\n",
    "        Learning_rate (float)\n",
    "        Fit_intercept (bool, com uma interceptação w0 ou não)\n",
    "    Retorna:\n",
    "        Numpy.ndarray, pesos aprendidos\n",
    "    \"\"\"\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    for iteration in range(max_iter):\n",
    "        weights = update_weights_gd(X_train, y_train, weights, learning_rate)\n",
    "        # Check the cost for every 100 (for example) iterations\n",
    "        if iteration % 100 == 0:\n",
    "            print(compute_cost(X_train, y_train, weights))\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo função que preve os resultados de novas entradas usando o medelo treinado \n",
    "def predict(X, weights):\n",
    "    if X.shape[1] == weights.shape[0] - 1:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "    return compute_prediction(X, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Nesse passo, importo as bases de dados que serão utilizadas para treinar o modelo (df_train = train.csv) e a base para testar o modelo treinado(df_teste = test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui o n_rows vai definir um limite de linhas a serem importadas das bases de dado, pois devido ao \n",
    "# tamanho dos arquivos, a memória do computador se tornou limitada. Sendo assim defini importar 1000000 \n",
    "# de linhas, para não sobrecarregar minha maquina.\n",
    "\n",
    "n_rows = 1000000  \n",
    "df_train = pd.read_csv('train.csv', nrows = n_rows)\n",
    "df_teste = pd.read_csv('test.csv', nrows = n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>29748</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>134</td>\n",
       "      <td>2017-11-06 16:21:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>124520</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-06 16:21:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>206446</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-06 16:21:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>167577</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>265</td>\n",
       "      <td>2017-11-06 16:21:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>121848</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>105</td>\n",
       "      <td>2017-11-06 16:21:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0        83230    3       1  13      379  2017-11-06 14:32:21             NaN   \n",
       "1        17357    3       1  19      379  2017-11-06 14:33:34             NaN   \n",
       "2        35810    3       1  13      379  2017-11-06 14:34:12             NaN   \n",
       "3        45745   14       1  13      478  2017-11-06 14:34:52             NaN   \n",
       "4       161007    3       1  13      379  2017-11-06 14:35:08             NaN   \n",
       "...        ...  ...     ...  ..      ...                  ...             ...   \n",
       "999995   29748    9       1  12      134  2017-11-06 16:21:51             NaN   \n",
       "999996  124520   12       1  15      178  2017-11-06 16:21:51             NaN   \n",
       "999997  206446   18       1  42      107  2017-11-06 16:21:51             NaN   \n",
       "999998  167577   12       1  13      265  2017-11-06 16:21:51             NaN   \n",
       "999999  121848   24       1  19      105  2017-11-06 16:21:51             NaN   \n",
       "\n",
       "        is_attributed  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "999995              0  \n",
       "999996              0  \n",
       "999997              0  \n",
       "999998              0  \n",
       "999999              0  \n",
       "\n",
       "[1000000 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrando a base de dados de treino que apresenta os seguintes atributos:\n",
    "# Ip: endereço ip do clique.\n",
    "# App: id do app para marketing.\n",
    "# Device: ID do tipo de dispositivo do telefone celular do usuário (por exemplo, iphone 6 plus, iphone 7, huawei mate 7 etc.)\n",
    "# Os: id da versão do sistema operacional do telefone celular do usuário\n",
    "# Channel: id do canal do editor de anúncios para celular\n",
    "# Click_time: data / hora do clique (UTC)\n",
    "# Attribute_time: se o usuário baixar o aplicativo depois de clicar em um anúncio, é o momento do download do aplicativo\n",
    "# Is_attributed: o destino que deve ser previsto, indicando que o aplicativo foi baixado\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5744</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>119901</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>72287</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>78477</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>123080</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999995</td>\n",
       "      <td>53436</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>376</td>\n",
       "      <td>2017-11-10 04:17:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999996</td>\n",
       "      <td>25714</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>125</td>\n",
       "      <td>2017-11-10 04:17:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999997</td>\n",
       "      <td>31139</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>477</td>\n",
       "      <td>2017-11-10 04:17:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999998</td>\n",
       "      <td>114636</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>439</td>\n",
       "      <td>2017-11-10 04:17:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999999</td>\n",
       "      <td>28661</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>469</td>\n",
       "      <td>2017-11-10 04:17:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        click_id      ip  app  device  os  channel           click_time\n",
       "0              0    5744    9       1   3      107  2017-11-10 04:00:00\n",
       "1              1  119901    9       1   3      466  2017-11-10 04:00:00\n",
       "2              2   72287   21       1  19      128  2017-11-10 04:00:00\n",
       "3              3   78477   15       1  13      111  2017-11-10 04:00:00\n",
       "4              4  123080   12       1  13      328  2017-11-10 04:00:00\n",
       "...          ...     ...  ...     ...  ..      ...                  ...\n",
       "999995    999995   53436   18       1  23      376  2017-11-10 04:17:35\n",
       "999996    999996   25714    6       1  13      125  2017-11-10 04:17:35\n",
       "999997    999997   31139   13       1  18      477  2017-11-10 04:17:35\n",
       "999998    999998  114636   18       1  78      439  2017-11-10 04:17:35\n",
       "999999    999999   28661    2       1  28      469  2017-11-10 04:17:35\n",
       "\n",
       "[1000000 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A base de teste é é um pouco diferente, os atributos 'atribute_time' e 'is_atribute' não estão presentes já que esse é o\n",
    "# objetivo do treinamento e é acrecentado o atributo 'click_id' que serve de referência.\n",
    "\n",
    "df_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando os dados de Treino  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora com os dados identificados,é preciso filtrar os que serão utlizados no treinamento.\n",
    "# Para o elemento X do treino, das 8 colunas disponiveis do df_train, serão utlizadas a colula 'app' e 'channel'\n",
    "# que serão correlacionadas com o elemento Y contendo 'is_tributed' que assume valor 0 e 1, sendo 1 quando o clicque \n",
    "# é completado com um download. \n",
    "# Já n_train é o número de amostras que vamos utlizar da nossa base de dados para treinar o modelo.\n",
    "\n",
    "X = df_train.drop(columns=['ip','device', 'os', 'click_time', 'attributed_time', 'is_attributed']).values\n",
    "Y = df_train['is_attributed'].values\n",
    "n_train = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciando o treinamento do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43154985790067246\n",
      "0.3025826107204381\n",
      "0.17737017017550225\n",
      "0.05692279128509142\n",
      "0.022405690925133382\n",
      "0.022128963129672254\n",
      "0.02203863084552145\n",
      "0.0219976261552673\n",
      "0.021972374027567132\n",
      "0.02195256196806824\n",
      "0.021934716381104422\n",
      "0.02191761045619345\n",
      "0.021900799230603594\n",
      "0.02188411878609412\n",
      "0.02186750816190703\n",
      "0.021850944539260512\n",
      "0.021834419322939263\n",
      "0.021817929241935766\n",
      "0.02180147302226457\n",
      "0.021785050139667386\n",
      "0.021768660351395373\n",
      "0.021752303520372288\n",
      "0.021735979549179517\n",
      "0.021719688355296946\n",
      "0.02170342986183449\n",
      "0.021687203994073232\n",
      "0.021671010678181453\n",
      "0.021654849840742042\n",
      "0.021638721408581224\n",
      "0.02162262530870809\n",
      "0.021606561468294493\n",
      "0.021590529814669114\n",
      "0.021574530275316316\n",
      "0.021558562777876704\n",
      "0.021542627250147633\n",
      "0.02152672362008423\n",
      "0.021510851815799738\n",
      "0.021495011765566393\n",
      "0.0214792033978158\n",
      "0.02146342664113938\n",
      "0.021447681424289048\n",
      "0.021431967676177305\n",
      "0.02141628532587784\n",
      "0.02140063430262584\n",
      "0.021385014535818446\n",
      "0.02136942595501493\n",
      "0.02135386848993726\n",
      "0.021338342070470244\n",
      "0.021322846626661982\n",
      "0.02130738208872409\n",
      "0.021291948387032068\n",
      "0.02127654545212558\n",
      "0.021261173214708672\n",
      "0.02124583160565018\n",
      "0.021230520555983838\n",
      "0.021215239996908625\n",
      "0.02119998985978908\n",
      "0.021184770076155313\n",
      "0.02116958057770348\n",
      "0.021154421296295862\n",
      "0.021139292163961147\n",
      "0.02112419311289452\n",
      "0.021109124075457925\n",
      "0.02109408498418034\n",
      "0.02107907577175774\n",
      "0.021064096371053456\n",
      "0.021049146715098242\n",
      "0.021034226737090392\n",
      "0.02101933637039593\n",
      "0.02100447554854876\n",
      "0.020989644205250683\n",
      "0.020974842274371637\n",
      "0.02096006968994973\n",
      "0.02094532638619133\n",
      "0.02093061229747115\n",
      "0.020915927358332375\n",
      "0.020901271503486675\n",
      "0.020886644667814307\n",
      "0.020872046786364146\n",
      "0.020857477794353704\n",
      "0.020842937627169232\n",
      "0.020828426220365723\n",
      "0.02081394350966689\n",
      "0.020799489430965247\n",
      "0.020785063920322023\n",
      "0.020770666913967274\n",
      "0.020756298348299833\n",
      "0.020741958159887157\n",
      "0.020727646285465563\n",
      "0.020713362661939943\n",
      "0.02069910722638386\n",
      "0.020684879916039504\n",
      "0.020670680668317534\n",
      "0.020656509420797147\n",
      "0.020642366111225906\n",
      "0.020628250677519677\n",
      "0.02061416305776262\n",
      "0.020600103190206994\n",
      "0.020586071013273116\n",
      "0.02057206646554927\n",
      "0.020558089485791537\n",
      "0.020544140012923685\n",
      "0.020530217986037113\n",
      "0.020516323344390665\n",
      "0.02050245602741046\n",
      "0.02048861597468977\n",
      "0.020474803125988875\n",
      "0.02046101742123495\n",
      "0.0204472588005218\n",
      "0.020433527204109757\n",
      "0.020419822572425448\n",
      "0.020406144846061704\n",
      "0.020392493965777195\n",
      "0.020378869872496454\n",
      "0.02036527250730956\n",
      "0.02035170181147177\n",
      "0.020338157726403662\n",
      "0.020324640193690572\n",
      "0.020311149155082656\n",
      "0.02029768455249427\n",
      "0.020284246328004192\n",
      "0.02027083442385506\n",
      "0.02025744878245317\n",
      "0.020244089346368344\n",
      "0.020230756058333594\n",
      "0.02021744886124474\n",
      "0.020204167698160348\n",
      "0.020190912512301335\n",
      "0.02017768324705066\n",
      "0.020164479845953136\n",
      "0.020151302252715015\n",
      "0.02013815041120382\n",
      "0.020125024265447947\n",
      "0.020111923759636358\n",
      "0.020098848838118345\n",
      "0.02008579944540319\n",
      "0.020072775526159742\n",
      "0.020059777025216215\n",
      "0.02004680388755983\n",
      "0.02003385605833641\n",
      "0.020020933482850153\n",
      "0.02000803610656316\n",
      "0.01999516387509523\n",
      "0.01998231673422338\n",
      "0.019969494629881544\n",
      "0.019956697508160263\n",
      "0.019943925315306196\n",
      "0.019931177997721917\n",
      "0.0199184555019653\n",
      "0.019905757774749504\n",
      "0.019893084762942194\n",
      "0.019880436413565503\n",
      "0.01986781267379537\n",
      "0.019855213490961386\n",
      "0.019842638812546203\n",
      "0.01983008858618529\n",
      "0.019817562759666417\n",
      "0.019805061280929348\n",
      "0.01979258409806542\n",
      "0.019780131159317003\n",
      "0.01976770241307733\n",
      "0.01975529780788989\n",
      "0.019742917292448058\n",
      "0.019730560815594673\n",
      "0.019718228326321755\n",
      "0.019705919773769797\n",
      "0.019693635107227662\n",
      "0.019681374276131904\n",
      "0.01966913723006641\n",
      "0.01965692391876208\n",
      "0.01964473429209626\n",
      "0.01963256830009229\n",
      "0.01962042589291922\n",
      "0.01960830702089126\n",
      "0.019596211634467228\n",
      "0.019584139684250424\n",
      "0.01957209112098786\n",
      "0.019560065895569943\n",
      "0.019548063959030148\n",
      "0.019536085262544325\n",
      "0.019524129757430432\n",
      "0.01951219739514805\n",
      "0.01950028812729789\n",
      "0.019488401905621323\n",
      "0.019476538682000045\n",
      "0.019464698408455494\n",
      "0.019452881037148432\n",
      "0.01944108652037858\n",
      "0.01942931481058401\n",
      "0.01941756586034073\n",
      "0.019405839622362413\n",
      "0.019394136049499657\n",
      "0.01938245509473974\n",
      "0.019370796711206048\n",
      "0.019359160852157675\n",
      "0.01934754747098895\n",
      "0.01933595652122901\n",
      "0.019324387956541296\n",
      "0.019312841730723177\n",
      "0.01930131779770536\n",
      "0.019289816111551603\n",
      "0.019278336626458187\n",
      "0.019266879296753445\n",
      "0.01925544407689733\n",
      "0.019244030921480977\n",
      "0.019232639785226317\n",
      "0.0192212706229855\n",
      "0.01920992338974057\n",
      "0.019198598040603008\n",
      "0.01918729453081321\n",
      "0.01917601281574016\n",
      "0.019164752850880946\n",
      "0.019153514591860373\n",
      "0.019142297994430416\n",
      "0.019131103014469943\n",
      "0.019119929607984212\n",
      "0.019108777731104504\n",
      "0.01909764734008762\n",
      "0.01908653839131559\n",
      "0.019075450841295118\n",
      "0.019064384646657353\n",
      "0.019053339764157313\n",
      "0.01904231615067366\n",
      "0.01903131376320816\n",
      "0.019020332558885383\n",
      "0.01900937249495232\n",
      "0.01899843352877793\n",
      "0.018987515617852866\n",
      "0.01897661871978908\n",
      "0.018965742792319402\n",
      "0.018954887793297247\n",
      "0.018944053680696266\n",
      "0.01893324041261\n",
      "0.01892244794725149\n",
      "0.01891167624295304\n",
      "0.018900925258165807\n",
      "0.01889019495145958\n",
      "0.01887948528152233\n",
      "0.018868796207160084\n",
      "0.018858127687296534\n",
      "0.01884747968097275\n",
      "0.0188368521473469\n",
      "0.018826245045694103\n",
      "0.01881565833540596\n",
      "0.018805091975990538\n",
      "0.018794545927071988\n",
      "0.018784020148390295\n",
      "0.018773514599801228\n",
      "0.01876302924127596\n",
      "0.018752564032900994\n",
      "0.018742118934877896\n",
      "0.018731693907523182\n",
      "0.018721288911268143\n",
      "0.018710903906658697\n",
      "0.018700538854355273\n",
      "0.01869019371513263\n",
      "0.018679868449879906\n",
      "0.01866956301960033\n",
      "0.01865927738541132\n",
      "0.018649011508544307\n",
      "0.018638765350344744\n",
      "0.018628538872272084\n",
      "0.01861833203589974\n",
      "0.018608144802915113\n",
      "0.018597977135119625\n",
      "0.01858782899442874\n",
      "0.018577700342872025\n",
      "0.018567591142593234\n",
      "0.018557501355850454\n",
      "0.018547430945016104\n",
      "0.018537379872577225\n",
      "0.018527348101135585\n",
      "0.018517335593407746\n",
      "0.018507342312225478\n",
      "0.018497368220535864\n",
      "0.01848741328140151\n",
      "0.018477477458000963\n",
      "0.018467560713628886\n",
      "0.01845766301169643\n",
      "0.018447784315731602\n",
      "0.0184379245893796\n",
      "0.018428083796403285\n",
      "0.018418261900683554\n",
      "0.018408458866219796\n",
      "0.018398674657130448\n",
      "0.01838890923765345\n",
      "0.01837916257214683\n",
      "0.018369434625089196\n",
      "0.01835972536108052\n",
      "0.01835003474484264\n",
      "0.01834036274121992\n",
      "0.01833070931518012\n",
      "0.01832107443181488\n",
      "0.018311458056340792\n",
      "0.018301860154099913\n",
      "0.018292280690560894\n",
      "0.018282719631319545\n",
      "0.018273176942100063\n",
      "0.01826365258875577\n",
      "0.018254146537270234\n",
      "0.018244658753758115\n",
      "0.018235189204466446\n",
      "0.01822573785577561\n",
      "0.01821630467420043\n",
      "0.01820688962639152\n",
      "0.018197492679136288\n",
      "0.01818811379936039\n",
      "0.01817875295412888\n",
      "0.018169410110647592\n",
      "0.018160085236264577\n",
      "0.018150778298471344\n",
      "0.018141489264904505\n",
      "0.01813221810334718\n",
      "0.0181229647817305\n",
      "0.018113729268135197\n",
      "0.01810451153079323\n",
      "0.018095311538089402\n",
      "0.01808612925856309\n",
      "0.01807696466090987\n",
      "0.01806781771398339\n",
      "0.018058688386797053\n",
      "0.01804957664852589\n",
      "0.01804048246850849\n",
      "0.018031405816248694\n",
      "0.018022346661417755\n",
      "0.018013304973856135\n",
      "0.018004280723575516\n",
      "0.017995273880760818\n",
      "0.01798628441577227\n",
      "0.017977312299147383\n",
      "0.01796835750160312\n",
      "0.017959419994037905\n",
      "0.017950499747533807\n",
      "0.017941596733358635\n",
      "0.01793271092296804\n",
      "0.017923842288007776\n",
      "0.017914990800315746\n",
      "0.017906156431924187\n",
      "0.017897339155061837\n",
      "0.0178885389421561\n",
      "0.01787975576583514\n",
      "0.017870989598930097\n",
      "0.017862240414477072\n",
      "0.01785350818571937\n",
      "0.017844792886109476\n",
      "0.01783609448931113\n",
      "0.01782741296920126\n",
      "0.017818748299872116\n",
      "0.017810100455632964\n",
      "0.017801469411012197\n",
      "0.017792855140758863\n",
      "0.017784257619844777\n",
      "0.01777567682346591\n",
      "0.017767112727044\n",
      "0.0177585653062284\n",
      "0.017750034536897105\n",
      "0.017741520395158403\n",
      "0.01773302285735198\n",
      "0.017724541900050066\n",
      "0.01771607750005857\n",
      "0.017707629634417826\n",
      "0.017699198280403512\n",
      "0.017690783415527166\n",
      "0.017682385017536804\n",
      "0.01767400306441717\n",
      "0.017665637534389995\n",
      "0.017657288405914014\n",
      "0.01764895565768476\n",
      "0.017640639268634285\n",
      "0.01763233921793064\n",
      "0.01762405548497724\n",
      "0.017615788049411857\n",
      "0.017607536891105578\n",
      "0.01759930199016148\n",
      "0.017591083326913018\n",
      "0.01758288088192244\n",
      "0.017574694635978643\n",
      "0.017566524570095006\n",
      "0.017558370665506962\n",
      "0.017550232903669236\n",
      "0.017542111266252953\n",
      "0.01753400573514246\n",
      "0.01752591629243184\n",
      "0.01751784292042121\n",
      "0.017509785601612808\n",
      "0.01750174431870679\n",
      "0.017493719054596676\n",
      "0.01748570979236477\n",
      "0.01747771651527708\n",
      "0.01746973920677815\n",
      "0.01746177785048552\n",
      "0.017453832430184106\n",
      "0.017445902929820088\n",
      "0.017437989333494844\n",
      "0.017430091625458458\n",
      "0.017422209790102942\n",
      "0.01741434381195555\n",
      "0.017406493675671517\n",
      "0.017398659366026817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017390840867910606\n",
      "0.017383038166317588\n",
      "0.01737525124634016\n",
      "0.017367480093160203\n",
      "0.017359724692041147\n",
      "0.01735198502831947\n",
      "0.017344261087396232\n",
      "0.017336552854728595\n",
      "0.017328860315821003\n",
      "0.017321183456216513\n",
      "0.017313522261487895\n",
      "0.01730587671722868\n",
      "0.017298246809044293\n",
      "0.01729063252254291\n",
      "0.017283033843326624\n",
      "0.017275450756982245\n",
      "0.017267883249072427\n",
      "0.01726033130512659\n",
      "0.017252794910632075\n",
      "0.01724527405102522\n",
      "0.01723776871168251\n",
      "0.017230278877911977\n",
      "0.017222804534944403\n",
      "0.01721534566792495\n",
      "0.0172079022619048\n",
      "0.017200474301832764\n",
      "0.017193061772547296\n",
      "0.017185664658768602\n",
      "0.017178282945090842\n",
      "0.017170916615974592\n",
      "0.017163565655739423\n",
      "0.01715623004855687\n",
      "0.01714890977844336\n",
      "0.017141604829253598\n",
      "0.017134315184674058\n",
      "0.017127040828216738\n",
      "0.017119781743213144\n",
      "0.0171125379128086\n",
      "0.01710530931995673\n",
      "0.01709809594741421\n",
      "0.01709089777773588\n",
      "0.01708371479326996\n",
      "0.017076546976153687\n",
      "0.017069394308309123\n",
      "0.017062256771439334\n",
      "0.017055134347024728\n",
      "0.0170480270163197\n",
      "0.01704093476034964\n",
      "0.017033857559908053\n",
      "0.01702679539555411\n",
      "0.017019748247610298\n",
      "0.017012716096160473\n",
      "0.017005698921048116\n",
      "0.01699869670187482\n",
      "0.016991709417999067\n",
      "0.016984737048535214\n",
      "0.016977779572352806\n",
      "0.01697083696807592\n",
      "0.01696390921408305\n",
      "0.016956996288506932\n",
      "0.016950098169234734\n",
      "0.016943214833908395\n",
      "0.016936346259925284\n",
      "0.016929492424438822\n",
      "0.016922653304359637\n",
      "0.01691582887635654\n",
      "0.016909019116857965\n",
      "0.016902224002053396\n",
      "0.01689544350789512\n",
      "0.016888677610099965\n",
      "0.016881926284151312\n",
      "0.016875189505301227\n",
      "0.016868467248572654\n",
      "0.016861759488761927\n",
      "0.01685506620044111\n",
      "0.016848387357960737\n",
      "0.016841722935452535\n",
      "0.016835072906832282\n",
      "0.016828437245802613\n",
      "0.016821815925856222\n",
      "0.01681520892027887\n",
      "0.016808616202152588\n",
      "0.016802037744358997\n",
      "0.01679547351958254\n",
      "0.016788923500313944\n",
      "0.016782387658853683\n",
      "0.016775865967315423\n",
      "0.016769358397629587\n",
      "0.016762864921546952\n",
      "0.016756385510642263\n",
      "0.016749920136317913\n",
      "0.01674346876980755\n",
      "0.01673703138217987\n",
      "0.016730607944342252\n",
      "0.016724198427044628\n",
      "0.016717802800883065\n",
      "0.016711421036303627\n",
      "0.016705053103606118\n",
      "0.016698698972947807\n",
      "0.016692358614347213\n",
      "0.016686031997687926\n",
      "0.016679719092722176\n",
      "0.016673419869074745\n",
      "0.016667134296246597\n",
      "0.01666086234361855\n",
      "0.016654603980455058\n",
      "0.016648359175907835\n",
      "0.01664212789901945\n",
      "0.016635910118726987\n",
      "0.01662970580386565\n",
      "0.01662351492317231\n",
      "0.016617337445289003\n",
      "0.016611173338766494\n",
      "0.01660502257206772\n",
      "0.016598885113571226\n",
      "0.016592760931574555\n",
      "0.016586649994297615\n",
      "0.016580552269886084\n",
      "0.016574467726414577\n",
      "0.016568396331889994\n",
      "0.016562338054254694\n",
      "0.016556292861389658\n",
      "0.016550260721117677\n",
      "0.016544241601206353\n",
      "0.016538235469371262\n",
      "0.0165322422932789\n",
      "0.016526262040549616\n",
      "0.016520294678760598\n",
      "0.016514340175448738\n",
      "0.016508398498113447\n",
      "0.016502469614219462\n",
      "0.0164965534911996\n",
      "0.016490650096457515\n",
      "0.016484759397370204\n",
      "0.016478881361290866\n",
      "0.016473015955551257\n",
      "0.01646716314746435\n",
      "0.016461322904326812\n",
      "0.016455495193421415\n",
      "0.01644967998201944\n",
      "0.01644387723738309\n",
      "0.016438086926767813\n",
      "0.016432309017424502\n",
      "0.01642654347660182\n",
      "0.016420790271548313\n",
      "0.016415049369514666\n",
      "0.01640932073775572\n",
      "0.016403604343532593\n",
      "0.016397900154114752\n",
      "0.016392208136781907\n",
      "0.016386528258826038\n",
      "0.016380860487553304\n",
      "0.016375204790285928\n",
      "0.01636956113436397\n",
      "0.016363929487147207\n",
      "0.016358309816016894\n",
      "0.016352702088377403\n",
      "0.016347106271658036\n",
      "0.01634152233331459\n",
      "0.016335950240831044\n",
      "0.01633038996172105\n",
      "0.01632484146352959\n",
      "0.016319304713834464\n",
      "0.01631377968024769\n",
      "0.016308266330417088\n",
      "0.01630276463202759\n",
      "0.016297274552802662\n",
      "0.01629179606050569\n",
      "0.016286329122941288\n",
      "0.01628087370795652\n",
      "0.01627542978344227\n",
      "0.01626999731733443\n",
      "0.01626457627761501\n",
      "0.016259166632313523\n",
      "0.016253768349507924\n",
      "0.01624838139732585\n",
      "0.016243005743945643\n",
      "0.016237641357597477\n",
      "0.016232288206564333\n",
      "0.016226946259183053\n",
      "0.016221615483845292\n",
      "0.016216295848998512\n",
      "0.016210987323146908\n",
      "0.016205689874852304\n",
      "0.016200403472735034\n",
      "0.01619512808547484\n",
      "0.01618986368181166\n",
      "0.016184610230546532\n",
      "0.01617936770054229\n",
      "0.016174136060724376\n",
      "0.01616891528008164\n",
      "0.016163705327666998\n",
      "0.01615850617259817\n",
      "0.016153317784058385\n",
      "0.016148140131297044\n",
      "0.01614297318363032\n",
      "0.016137816910441916\n",
      "0.016132671281183487\n",
      "0.016127536265375417\n",
      "0.01612241183260728\n",
      "0.01611729795253848\n",
      "0.016112194594898682\n",
      "0.016107101729488437\n",
      "0.01610201932617965\n",
      "0.016096947354916017\n",
      "0.01609188578571363\n",
      "0.016086834588661295\n",
      "0.016081793733921025\n",
      "0.016076763191728523\n",
      "0.016071742932393492\n",
      "0.016066732926300144\n",
      "0.016061733143907422\n",
      "0.01605674355574957\n",
      "0.016051764132436298\n",
      "0.016046794844653295\n",
      "0.016041835663162415\n",
      "0.016036886558802053\n",
      "0.016031947502487456\n",
      "0.01602701846521098\n",
      "0.016022099418042394\n",
      "0.016017190332129127\n",
      "0.016012291178696566\n",
      "0.016007401929048228\n",
      "0.016002522554566013\n",
      "0.015997653026710464\n",
      "0.01599279331702095\n",
      "0.01598794339711582\n",
      "0.015983103238692675\n",
      "0.015978272813528482\n",
      "0.015973452093479765\n",
      "0.01596864105048275\n",
      "0.01596383965655356\n",
      "0.01595904788378827\n",
      "0.01595426570436311\n",
      "0.01594949309053457\n",
      "0.015944730014639464\n",
      "0.01593997644909513\n",
      "0.015935232366399415\n",
      "0.015930497739130852\n",
      "0.01592577253994867\n",
      "0.015921056741592932\n",
      "0.015916350316884553\n",
      "0.01591165323872534\n",
      "0.01590696548009813\n",
      "0.015902287014066707\n",
      "0.015897617813775942\n",
      "0.01589295785245176\n",
      "0.015888307103401195\n",
      "0.015883665540012377\n",
      "0.01587903313575455\n",
      "0.015874409864178114\n",
      "0.015869795698914516\n",
      "0.015865190613676368\n",
      "0.015860594582257338\n",
      "0.015856007578532196\n",
      "0.01585142957645669\n",
      "0.015846860550067662\n",
      "0.01584230047348284\n",
      "0.015837749320900922\n",
      "0.015833207066601455\n",
      "0.015828673684944814\n",
      "0.01582414915037219\n",
      "0.015819633437405396\n",
      "0.01581512652064694\n",
      "0.015810628374779843\n",
      "0.015806138974567688\n",
      "0.01580165829485434\n",
      "0.015797186310564107\n",
      "0.01579272299670146\n",
      "0.015788268328351004\n",
      "0.015783822280677387\n",
      "0.015779384828925252\n",
      "0.01577495594841898\n",
      "0.015770535614562754\n",
      "0.015766123802840332\n",
      "0.01576172048881497\n",
      "0.015757325648129313\n",
      "0.015752939256505283\n",
      "0.015748561289743886\n",
      "0.01574419172372516\n",
      "0.01573983053440801\n",
      "0.015735477697830094\n",
      "0.015731133190107625\n",
      "0.015726796987435336\n",
      "0.015722469066086237\n",
      "0.015718149402411542\n",
      "0.015713837972840466\n",
      "0.015709534753880074\n",
      "0.015705239722115186\n",
      "0.015700952854208226\n",
      "0.015696674126898947\n",
      "0.015692403517004357\n",
      "0.015688141001418642\n",
      "0.015683886557112784\n",
      "0.01567964016113463\n",
      "0.015675401790608546\n",
      "0.015671171422735348\n",
      "0.015666949034792075\n",
      "0.01566273460413186\n",
      "0.01565852810818373\n",
      "0.015654329524452396\n",
      "0.015650138830518162\n",
      "0.01564595600403664\n",
      "0.015641781022738662\n",
      "0.015637613864429988\n",
      "0.015633454506991305\n",
      "0.01562930292837777\n",
      "0.015625159106619074\n",
      "0.015621023019819151\n",
      "0.015616894646155923\n",
      "0.015612773963881235\n",
      "0.01560866095132056\n",
      "0.015604555586872846\n",
      "0.015600457849010341\n",
      "0.015596367716278405\n",
      "0.015592285167295163\n",
      "0.015588210180751579\n",
      "0.015584142735410984\n",
      "0.015580082810109015\n",
      "0.015576030383753443\n",
      "0.015571985435323898\n",
      "0.015567947943871648\n",
      "0.015563917888519496\n",
      "0.015559895248461488\n",
      "0.015555880002962718\n",
      "0.015551872131359149\n",
      "0.01554787161305743\n",
      "0.015543878427534616\n",
      "0.015539892554337981\n",
      "0.015535913973084885\n",
      "0.015531942663462467\n",
      "0.015527978605227498\n",
      "0.015524021778206125\n",
      "0.015520072162293709\n",
      "0.01551612973745459\n",
      "0.015512194483721846\n",
      "0.015508266381197157\n",
      "0.015504345410050467\n",
      "0.015500431550519972\n",
      "0.015496524782911693\n",
      "0.015492625087599384\n",
      "0.01548873244502429\n",
      "0.015484846835694963\n",
      "0.015480968240186972\n",
      "0.01547709663914279\n",
      "0.015473232013271485\n",
      "0.01546937434334857\n",
      "0.015465523610215769\n",
      "0.015461679794780797\n",
      "0.015457842878017188\n",
      "0.015454012840963963\n",
      "0.015450189664725562\n",
      "0.015446373330471524\n",
      "0.015442563819436372\n",
      "0.015438761112919253\n",
      "0.015434965192283859\n",
      "0.015431176038958157\n",
      "0.015427393634434171\n",
      "0.015423617960267779\n",
      "0.01541984899807849\n",
      "0.015416086729549238\n",
      "0.015412331136426169\n",
      "0.015408582200518408\n",
      "0.015404839903697884\n",
      "0.015401104227899054\n",
      "0.015397375155118787\n",
      "0.015393652667416012\n",
      "0.015389936746911635\n",
      "0.01538622737578828\n",
      "0.015382524536290031\n",
      "0.01537882821072227\n",
      "0.015375138381451482\n",
      "0.015371455030904986\n",
      "0.015367778141570745\n",
      "0.015364107695997185\n",
      "0.015360443676792946\n",
      "0.015356786066626684\n",
      "0.015353134848226873\n",
      "0.015349490004381522\n",
      "0.01534585151793811\n",
      "0.015342219371803233\n",
      "0.01533859354894245\n",
      "0.015334974032380133\n",
      "0.015331360805199125\n",
      "0.015327753850540641\n",
      "0.015324153151604031\n",
      "0.015320558691646596\n",
      "0.01531697045398326\n",
      "0.015313388421986549\n",
      "0.015309812579086248\n",
      "0.015306242908769219\n",
      "0.01530267939457927\n",
      "0.015299122020116839\n",
      "0.015295570769038855\n",
      "0.01529202562505856\n",
      "0.015288486571945202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015284953593523935\n",
      "0.015281426673675564\n",
      "0.01527790579633639\n",
      "0.01527439094549791\n",
      "0.015270882105206766\n",
      "0.015267379259564333\n",
      "0.015263882392726746\n",
      "0.015260391488904545\n",
      "0.015256906532362538\n",
      "0.015253427507419596\n",
      "0.015249954398448432\n",
      "0.015246487189875419\n",
      "0.015243025866180392\n",
      "0.015239570411896441\n",
      "0.01523612081160974\n",
      "0.015232677049959335\n",
      "0.015229239111636924\n",
      "0.015225806981386706\n",
      "0.015222380644005109\n",
      "0.015218960084340722\n",
      "0.015215545287293996\n",
      "0.015212136237817081\n",
      "0.015208732920913685\n",
      "0.015205335321638723\n",
      "0.015201943425098362\n",
      "0.015198557216449617\n",
      "0.015195176680900304\n",
      "0.015191801803708759\n",
      "0.015188432570183664\n",
      "0.015185068965683965\n",
      "0.01518171097561851\n",
      "0.015178358585445976\n",
      "0.015175011780674643\n",
      "0.015171670546862253\n",
      "0.015168334869615788\n",
      "0.015165004734591212\n",
      "0.015161680127493452\n",
      "0.015158361034076064\n",
      "0.015155047440141149\n",
      "0.015151739331539096\n",
      "0.015148436694168443\n",
      "0.015145139513975689\n",
      "0.01514184777695508\n",
      "0.015138561469148515\n",
      "0.015135280576645245\n",
      "0.01513200508558178\n",
      "0.015128734982141689\n",
      "0.015125470252555432\n",
      "0.015122210883100113\n",
      "0.015118956860099427\n",
      "0.01511570816992336\n",
      "0.015112464798988085\n",
      "0.01510922673375578\n",
      "0.01510599396073443\n",
      "0.015102766466477657\n",
      "0.015099544237584571\n",
      "0.015096327260699557\n",
      "0.015093115522512142\n",
      "0.01508990900975683\n",
      "0.015086707709212832\n",
      "0.015083511607704027\n",
      "0.015080320692098723\n",
      "0.015077134949309503\n",
      "0.015073954366293038\n",
      "0.015070778930049947\n",
      "0.015067608627624587\n",
      "0.015064443446104957\n",
      "0.015061283372622459\n",
      "0.015058128394351748\n",
      "0.015054978498510578\n",
      "0.015051833672359698\n",
      "0.015048693903202575\n",
      "0.015045559178385277\n",
      "0.015042429485296358\n",
      "0.015039304811366576\n",
      "0.015036185144068914\n",
      "0.01503307047091822\n",
      "0.0150299607794712\n",
      "0.01502685605732617\n",
      "0.015023756292122914\n",
      "0.015020661471542568\n",
      "0.015017571583307403\n",
      "0.01501448661518068\n",
      "0.015011406554966553\n",
      "0.01500833139050982\n",
      "0.015005261109695807\n",
      "0.015002195700450272\n",
      "0.014999135150739133\n",
      "0.014996079448568398\n",
      "0.014993028581983998\n",
      "0.014989982539071625\n",
      "0.014986941307956556\n",
      "0.01498390487680354\n",
      "0.01498087323381665\n",
      "0.014977846367239074\n",
      "0.014974824265353006\n",
      "0.014971806916479527\n",
      "0.014968794308978387\n",
      "0.014965786431247909\n",
      "0.014962783271724824\n",
      "0.014959784818884131\n",
      "0.014956791061238903\n",
      "0.014953801987340226\n",
      "0.014950817585776979\n",
      "0.014947837845175711\n",
      "0.014944862754200513\n",
      "0.014941892301552883\n",
      "0.014938926475971535\n",
      "0.014935965266232285\n",
      "0.014933008661147922\n",
      "0.014930056649568006\n",
      "0.014927109220378864\n",
      "0.014924166362503238\n",
      "0.014921228064900332\n",
      "0.014918294316565614\n",
      "0.014915365106530631\n",
      "0.014912440423862925\n",
      "0.014909520257665862\n",
      "0.014906604597078507\n",
      "0.014903693431275494\n",
      "0.014900786749466925\n",
      "0.0148978845408981\n",
      "0.014894986794849545\n",
      "0.014892093500636782\n",
      "0.014889204647610215\n",
      "0.014886320225155021\n",
      "0.014883440222690988\n",
      "0.01488056462967237\n",
      "0.014877693435587789\n",
      "0.014874826629960076\n",
      "0.014871964202346176\n",
      "0.014869106142336991\n",
      "0.014866252439557246\n",
      "0.014863403083665327\n",
      "0.01486055806435327\n",
      "0.014857717371346491\n",
      "0.014854880994403748\n",
      "0.014852048923316985\n",
      "0.014849221147911183\n",
      "0.014846397658044293\n",
      "0.014843578443607031\n",
      "0.014840763494522846\n",
      "0.014837952800747685\n",
      "0.014835146352269983\n",
      "0.014832344139110436\n",
      "0.014829546151321957\n",
      "0.014826752378989505\n",
      "0.014823962812229996\n",
      "0.014821177441192145\n",
      "0.014818396256056356\n",
      "0.014815619247034626\n",
      "0.01481284640437041\n",
      "0.014810077718338468\n",
      "0.014807313179244804\n",
      "0.014804552777426507\n",
      "0.014801796503251625\n",
      "0.014799044347119112\n",
      "0.01479629629945861\n",
      "0.01479355235073041\n",
      "0.01479081249142529\n",
      "0.014788076712064467\n",
      "0.01478534500319938\n",
      "0.014782617355411656\n",
      "0.014779893759312965\n",
      "0.014777174205544885\n",
      "0.014774458684778839\n",
      "0.014771747187715959\n",
      "0.014769039705086912\n",
      "0.014766336227651913\n",
      "0.014763636746200522\n",
      "0.014760941251551488\n",
      "0.014758249734552786\n",
      "0.014755562186081426\n",
      "0.014752878597043285\n",
      "0.014750198958373047\n",
      "0.014747523261034182\n",
      "0.014744851496018679\n",
      "0.014742183654347017\n",
      "0.014739519727068098\n",
      "0.01473685970525906\n",
      "0.014734203580025189\n",
      "0.014731551342499902\n",
      "0.014728902983844452\n",
      "0.014726258495248043\n",
      "0.014723617867927556\n",
      "0.014720981093127555\n",
      "0.014718348162120065\n",
      "0.014715719066204601\n",
      "0.014713093796707962\n",
      "0.014710472344984208\n",
      "0.014707854702414428\n",
      "0.014705240860406862\n",
      "0.014702630810396541\n",
      "0.014700024543845336\n",
      "0.01469742205224186\n",
      "0.014694823327101356\n",
      "0.014692228359965476\n",
      "0.01468963714240237\n",
      "0.014687049666006462\n",
      "0.014684465922398391\n",
      "0.014681885903224905\n",
      "0.01467930960015879\n",
      "0.014676737004898726\n",
      "0.014674168109169196\n",
      "0.014671602904720419\n"
     ]
    }
   ],
   "source": [
    "# Aqui treinaremos o modelo com 100000 iterações numa taxa de aprendizado de 0,01.\n",
    "# Utilizei a Função timeit para demonstrar o tempo que se leva ao realizar esse treinamento usando a \n",
    "# a tecnica de regressão usando o gradiente descendente. As saídas demonstram que o modelo vai ficando\n",
    "# mais preciso com o passar das iterações.\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "weights = train_logistic_regression(X, Y, max_iter=100000, learning_rate=0.01, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo gasto para realizar o treinamento do modelo:  4436.81 segundos.\n"
     ]
    }
   ],
   "source": [
    "# Tempo levado para treinar o modelo baseado em regressão gradiente descendente.\n",
    "print (\"Tempo gasto para realizar o treinamento do modelo: % 0.2f segundos.\"% (timeit.default_timer () -start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando os dados de teste do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9, 107],\n",
       "       [  9, 466],\n",
       "       [ 21, 128],\n",
       "       ...,\n",
       "       [ 13, 477],\n",
       "       [ 18, 439],\n",
       "       [  2, 469]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aqui usando df_teste selecionaremos X_test contendo as colunas 'app' e 'channel' as mesma utilizadas \n",
    "# em X da base df_train.\n",
    "\n",
    "X_test = df_teste.drop(columns=['click_id','ip', 'device', 'os', 'click_time']).values\n",
    "Y_test = df_train['is_attributed'].values\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando a predição dos dados teste com o modelo treinado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(X_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras de treinamento: 100000, Cobertura de precisação alcançada:0.501\n"
     ]
    }
   ],
   "source": [
    "# Obtendo e mostrando a cobertura de precisão que o modelo tilizando regressão por gradiente descendente alcançou \n",
    "# com os dados de 100000 amostras:\n",
    "print('Amostras de treinamento: {0}, Cobertura de precisação alcançada:{1:.3f}'.format(n_train, roc_auc_score(Y_test, predictions)))\n",
    "cobertura_RGD = roc_auc_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agora farei o treinamento me basendo na abordagem de regressão logística usando  gradiente estocástico\n",
    "#### Porém aqui utlizarei o módulo SDGClassifier do scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os parametros do SDG\n",
    "\n",
    "sgd_lr = SGDClassifier(loss='log', penalty=None, fit_intercept=True, learning_rate='constant', eta0=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo SDG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.01, learning_rate='constant', loss='log', penalty=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo SDG e marcando tempo para tal\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "sgd_lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo gasto para realizar o treinamento do modelo com SDG:  6.33 segundos.\n"
     ]
    }
   ],
   "source": [
    "print (\"Tempo gasto para realizar o treinamento do modelo com SDG: % 0.2f segundos.\"% (timeit.default_timer () -start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando a predição do modelo treinado com SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sgd_lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras de treinamento: 100000, Cobertura de precisação alcançada:0.500\n"
     ]
    }
   ],
   "source": [
    "# Obtendo e mostrando a cobertura e precisão do modelo treinado em SDG.\n",
    "\n",
    "print('Amostras de treinamento: {0}, Cobertura de precisação alcançada:{1:.3f}'.format(n_train, roc_auc_score(Y_test, pred)))\n",
    "cobertura_SDG = roc_auc_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões \n",
    "#### RGD > tempo de treino: 4436.81 segundos e cobertura: 0.501\n",
    "#### SDG > tempo de treino: 6.33 segundos e cobertura: 0.500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####      Utilizando o modelo de treinamento baseado em regressão logística de gradiente descendente foi possivel alcançar uma cobertura de 0.501. O resultado obtido poderá não ser muito útil dada a exigencia de cobertura. Outro problema dessa abordagem é o tempo de execução para treinar o modelo, pois apesar de não ser usado toda  a base de dados e treinar com 100000 interações a uma taxa de 0,01 custou um tempo muito grande. Se o conjunto de dados fosse maior, o que é muito possível de acontecer, o tempo para treinar o modelo aumenteria exponencialmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O segundo exemplo, o modelo de treinamento de regressão logística usando descida do gradiente estocástico usando o módulo SDGClassifier do scikit-learn. Nessa abordagem, obtivemos uma grande melhora no quesito tempo de aprendizado do modelo e foi obtido uma cobertura semelhante de precisão com o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
